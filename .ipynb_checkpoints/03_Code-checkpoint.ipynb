{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7604d93-723d-4323-817f-18ebaf733466",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e32e94b4-98b8-4405-9ff3-e11452ec0dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b7d92a-661c-468f-bba6-242e27be33d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fb800b2c-9e93-46a1-bdb0-948cf0845fc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting python-utils\n",
      "  Downloading python_utils-3.9.1-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Requirement already satisfied: typing_extensions>3.10.0.2 in /opt/conda/lib/python3.12/site-packages (from python-utils) (4.12.2)\n",
      "Downloading python_utils-3.9.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: python-utils\n",
      "Successfully installed python-utils-3.9.1\n"
     ]
    }
   ],
   "source": [
    "!pip install python-utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "78632d1e-3ddc-4fa5-a865-d0bedd545ab6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in /opt/conda/lib/python3.12/site-packages (4.66.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm  # or another package if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "200d86a8-c3f2-46a0-bf9d-93f0e17ca24c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'progress_bar' from 'utils' (/opt/conda/lib/python3.12/site-packages/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m progress_bar, simple_FC\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'progress_bar' from 'utils' (/opt/conda/lib/python3.12/site-packages/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "from utils import progress_bar, simple_FC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8031ce1a-9bfb-4bac-beb3-63abe1a3fa69",
   "metadata": {},
   "source": [
    "# Code du papier brut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "308d1559-d9b7-454a-a26b-b930d2738b18",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'simple_FC' from 'utils' (/opt/conda/lib/python3.12/site-packages/utils/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m#from utils import progress_bar\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m simple_FC\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtrain\u001b[39m(epoch, net):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'simple_FC' from 'utils' (/opt/conda/lib/python3.12/site-packages/utils/__init__.py)"
     ]
    }
   ],
   "source": [
    "'''Train MNIST with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "#from utils import progress_bar\n",
    "from utils import simple_FC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def train(epoch, net):\n",
    "    if args.verbose:\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "    net.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        targets = torch.nn.functional.one_hot(targets, num_classes=10).float()\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += targets.size(0)\n",
    "        correct += predicted.eq(targets.argmax(1)).sum().item()\n",
    "        if args.verbose:\n",
    "            progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                     % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    return 100.*correct/total, train_loss/(batch_idx+1)\n",
    "\n",
    "\n",
    "def test(epoch, net, model_name, save_checkpoint=False):\n",
    "    global best_acc\n",
    "    net.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            targets = torch.nn.functional.one_hot(targets, num_classes=10).float()\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets.argmax(1)).sum().item()\n",
    "            if args.verbose:\n",
    "                progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "    acc = 100.*correct/total\n",
    "    if save_checkpoint:\n",
    "        print('Saving..')\n",
    "        state = {\n",
    "            'net': net.state_dict(),\n",
    "            'acc': acc,\n",
    "            'epoch': epoch,\n",
    "        }\n",
    "        torch.save(state, os.path.join(args.ckpt_path, '%s.pth'%model_name))\n",
    "        best_acc = acc\n",
    "    return 100.*correct/total, test_loss/(batch_idx+1)\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Double Descent Curve')\n",
    "parser.add_argument('--verbose', default=0, type=int, help='level of verbos')\n",
    "parser.add_argument('--reuse', action='store_true', help='parameter reuse')\n",
    "parser.add_argument('--data_path', default='./data', type=str, help='data directory')\n",
    "parser.add_argument('--ckpt_path', default='./ckpt', type=str, help='checkpoint directory')\n",
    "parser.add_argument('--log_path', default='./log', type=str, help='log directory')\n",
    "args = parser.parse_args()\n",
    "\n",
    "if not os.path.isdir(args.data_path):\n",
    "    os.mkdir(args.data_path)\n",
    "if not os.path.isdir(args.ckpt_path):\n",
    "    os.mkdir(args.ckpt_path)\n",
    "if not os.path.isdir(args.log_path):\n",
    "    os.mkdir(args.log_path)\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Data: no data augmentation is used\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path, train=True, download=True, transform=transform_train)\n",
    "trainset = torch.utils.data.Subset(trainset, indices=np.arange(4000))\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path, train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "n_hidden_units = [1, 3, 5, 7, 9, 10, 20, 30, 40, 45, 47, 49, 50, 51, 53, 55, 60, 70, 80, 90, 100, 110, 130, 150, 170, 200, 250]\n",
    "n_epoch = 6000\n",
    "\n",
    "for n_hidden_unit in n_hidden_units:\n",
    "    # Model\n",
    "    net = simple_FC(n_hidden_unit)\n",
    "    print('Number of parameters: %d'%sum(p.numel() for p in net.parameters()))\n",
    "    net = net.cuda()\n",
    "    net = net.to(device)\n",
    "    if device == 'cuda':\n",
    "        net = net.cuda()\n",
    "        cudnn.benchmark = True\n",
    "    ### initialization\n",
    "    if n_hidden_unit == 1: # smallest network\n",
    "        torch.nn.init.xavier_uniform_(net.features[1].weight, gain=1.0)\n",
    "        torch.nn.init.xavier_uniform_(net.classifier.weight, gain=1.0)\n",
    "    elif n_hidden_unit > 50: # interpolation point: Number of data (4000) * number of class (10) = number of parameters (50*784 + 50 + 50*10 + 10)\n",
    "        torch.nn.init.normal_(net.features[1].weight, mean=0.0, std=0.1)\n",
    "        torch.nn.init.normal_(net.classifier.weight, mean=0.0, std=0.1)\n",
    "    else: \n",
    "        torch.nn.init.normal_(net.features[1].weight, mean=0.0, std=0.1)\n",
    "        torch.nn.init.normal_(net.classifier.weight, mean=0.0, std=0.1)\n",
    "        if args.reuse:\n",
    "            print('use previous checkpoints to initialize the weights')\n",
    "            i = 1 # load the closest previous model for weight reuse\n",
    "            while not os.path.exists(os.path.join(args.ckpt_path, 'simple_FC_%d.pth'%(n_hidden_unit-i))):\n",
    "                print('loading from simple_FC_%d.pth'%(n_hidden_unit-i))\n",
    "                i += 1\n",
    "            checkpoint = torch.load(os.path.join(args.ckpt_path, 'simple_FC_%d.pth'%(n_hidden_unit-i)))\n",
    "            with torch.no_grad():\n",
    "                net.features[1].weight[:n_hidden_unit-i, :].copy_(checkpoint['net']['features.1.weight'])\n",
    "                net.features[1].bias[:n_hidden_unit-i].copy_(checkpoint['net']['features.1.bias'])\n",
    "                net.classifier.weight[:, :n_hidden_unit-i].copy_(checkpoint['net']['classifier.weight'])\n",
    "                net.classifier.bias.copy_(checkpoint['net']['classifier.bias'])\n",
    "    ### training and testing\n",
    "    best_acc = 0\n",
    "    start_epoch = 0\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.95)\n",
    "    for epoch in range(start_epoch, start_epoch+n_epoch):\n",
    "        if (epoch+1) % 500 == 0:\n",
    "            if n_hidden_unit <= 50: # learning rate schedule\n",
    "                optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] * 0.9\n",
    "        train_acc, train_loss = train(epoch, net)\n",
    "        if n_hidden_unit <= 50 and train_acc == 1 or epoch == start_epoch+n_epoch-1: # early stop before interpolation\n",
    "            test_acc, test_loss = test(epoch, net, 'simple_FC_%d'%(n_hidden_unit), save_checkpoint=True)\n",
    "            print('classification error reaches 0, stop training')\n",
    "            break\n",
    "    print('Training Loss: %.3f | Acc: %.3f%%' % (train_loss, train_acc))\n",
    "    print('Test Loss: %.3f | Acc: %.3f%%\\n' % (test_loss, test_acc))\n",
    "    with open(os.path.join(args.log_path, 'FC_%d.txt'%n_hidden_unit), 'w') as fw:\n",
    "        fw.write('Number of parameters: %d\\n'%sum(p.numel() for p in net.parameters()))\n",
    "        fw.write('Training Loss: %.3f | Acc: %.3f%%\\n' % (train_loss, train_acc))\n",
    "        fw.write('Test Loss: %.3f | Acc: %.3f%%\\n' % (test_loss, test_acc))\n",
    "\n",
    "\n",
    "\n",
    "model_names = sorted([int(fn.split('_')[1].split('.')[0]) for fn in os.listdir(args.log_path)])\n",
    "\n",
    "train_losses = {model_name:0. for model_name in model_names}\n",
    "test_losses = {model_name:0. for model_name in model_names}\n",
    "train_accs = {model_name:0. for model_name in model_names}\n",
    "test_accs = {model_name:0. for model_name in model_names}\n",
    "n_params = {model_name:0. for model_name in model_names}\n",
    "\n",
    "for model_name in model_names:\n",
    "    with open(os.path.join('log', 'FC_%d.txt'%(model_name))) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('Number'):\n",
    "                n_params[model_name] = float(line.rstrip().split()[-1])\n",
    "            if line.startswith('Training'):\n",
    "                loss = re.search(r'Loss: (.*?) \\|', line).group(1)\n",
    "                train_losses[model_name] = float(loss)\n",
    "                acc = re.search(r'Acc: (.*?)\\%', line).group(1)\n",
    "                train_accs[model_name] = float(acc)\n",
    "            if line.startswith('Test'):\n",
    "                loss = re.search(r'Loss: (.*?) \\|', line).group(1)\n",
    "                test_losses[model_name] = float(loss)\n",
    "                acc = re.search(r'Acc: (.*?)\\%', line).group(1)\n",
    "                test_accs[model_name] = float(acc)\n",
    "\n",
    "\n",
    "# plot \n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "plt.plot([n_params[model_name] for model_name in model_names], [train_losses[model_name] for model_name in model_names], marker='o', label='train', color='#e31a1c')\n",
    "plt.plot([n_params[model_name] for model_name in model_names], [test_losses[model_name] for model_name in model_names], marker='o', label='test', color='#1f78b4')\n",
    "plt.ylabel('loss')\n",
    "box = ax.get_position()\n",
    "plt.tight_layout()\n",
    "ax.set_position([box.x0, box.y0,\n",
    "             box.width, box.height * 0.9])\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.25), fancybox=True, ncol=4)\n",
    "if args.reuse:\n",
    "    plt.savefig('MNIST_double_descent_loss_w_weight_reuse.png')\n",
    "else:\n",
    "    plt.savefig('MNIST_double_descent_loss_wo_weight_reuse.png')\n",
    "\n",
    "plt.clf()\n",
    "fig = plt.figure()\n",
    "ax = plt.subplot(111)\n",
    "plt.plot([n_params[model_name] for model_name in model_names], [train_accs[model_name] for model_name in model_names], marker='o', label='train', color='#e31a1c')\n",
    "plt.plot([n_params[model_name] for model_name in model_names], [test_accs[model_name] for model_name in model_names], marker='o', label='test', color='#1f78b4')\n",
    "plt.ylabel('accuracy')\n",
    "box = ax.get_position()\n",
    "plt.tight_layout()\n",
    "ax.set_position([box.x0, box.y0,\n",
    "             box.width, box.height * 0.9])\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.25), fancybox=True, ncol=4)\n",
    "if args.reuse:\n",
    "    plt.savefig('MNIST_double_descent_accuracy_w_weight_reuse.png')\n",
    "else:\n",
    "    plt.savefig('MNIST_double_descent_accuracy_wo_weight_reuse.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6c398ff-7abe-4ee2-9519-2f831e45f0b6",
   "metadata": {},
   "source": [
    "# Ajout commentaires sur code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e35dbffd-6e07-40f3-b7d3-bd8a16977d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Train MNIST with PyTorch.'''\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os\n",
    "import re\n",
    "import argparse\n",
    "import numpy as np\n",
    "\n",
    "from utils import progress_bar, simple_FC\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Fonction d'entraînement d'un modèle pour une époque donnée\n",
    "def train(epoch, net):\n",
    "    # Si 'verbose' est activé, afficher l'indice de l'époque en cours\n",
    "    if args.verbose:\n",
    "        print('\\nEpoch: %d' % epoch)\n",
    "\n",
    "    # Passer le réseau en mode entraînement (cela active des comportements comme la régularisation par dropout)\n",
    "    net.train()\n",
    "\n",
    "    # Initialisation des variables pour suivre la perte (loss) et l'exactitude (accuracy) pendant l'entraînement\n",
    "    train_loss = 0  # Somme des pertes (loss) pour la période\n",
    "    correct = 0      # Nombre de prédictions correctes\n",
    "    total = 0        # Nombre total de données traitées\n",
    "\n",
    "    # Boucle sur les mini-batches du DataLoader d'entraînement\n",
    "    for batch_idx, (inputs, targets) in enumerate(trainloader):\n",
    "        # Conversion des labels (cibles) en encodage one-hot et en type float\n",
    "        targets = torch.nn.functional.one_hot(targets, num_classes=10).float()\n",
    "        \n",
    "        # Transférer les entrées et les cibles sur le bon périphérique (CPU ou GPU)\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "        # Réinitialiser les gradients des paramètres du modèle avant le calcul\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Effectuer une passe avant dans le réseau pour obtenir les prédictions\n",
    "        outputs = net(inputs)\n",
    "\n",
    "        # Calcul de la perte entre les sorties du modèle et les cibles (labels)\n",
    "        loss = criterion(outputs, targets)\n",
    "\n",
    "        # Rétropropagation de la perte pour calculer les gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Mise à jour des poids du modèle en fonction des gradients\n",
    "        optimizer.step()\n",
    "\n",
    "        # Accumuler la perte totale de l'entraînement\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        # Trouver l'indice de la classe prédite (la classe avec la plus grande probabilité)\n",
    "        _, predicted = outputs.max(1)\n",
    "\n",
    "        # Ajouter le nombre total d'exemples traités dans ce mini-batch\n",
    "        total += targets.size(0)\n",
    "\n",
    "        # Comparer les prédictions avec les cibles pour calculer le nombre de prédictions correctes\n",
    "        # `predicted.eq(targets.argmax(1))` renvoie un vecteur booléen où True indique que la prédiction est correcte\n",
    "        correct += predicted.eq(targets.argmax(1)).sum().item()\n",
    "\n",
    "        # Si 'verbose' est activé, afficher une barre de progression avec la perte moyenne et la précision actuelle\n",
    "        if args.verbose:\n",
    "            progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                         % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Retourner l'exactitude en pourcentage et la perte moyenne sur l'époque\n",
    "    return 100.*correct/total, train_loss/(batch_idx+1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def test(epoch, net, model_name, save_checkpoint=False):\n",
    "    # Déclare une variable globale 'best_acc' qui est utilisée pour suivre la meilleure précision obtenue sur les tests.\n",
    "    global best_acc\n",
    "    \n",
    "    # Place le réseau de neurones en mode évaluation (inhibe la mise à jour des gradients et les mécanismes comme Dropout et BatchNorm)\n",
    "    net.eval()\n",
    "\n",
    "    # Initialisation de variables pour suivre la perte de test et la précision\n",
    "    test_loss = 0  # Somme des pertes pour toutes les étapes de test\n",
    "    correct = 0     # Nombre de prédictions correctes\n",
    "    total = 0       # Nombre total d'exemples traités\n",
    "\n",
    "    # Utilisation de 'torch.no_grad()' pour indiquer que les gradients ne seront pas calculés durant la phase de test\n",
    "    # Cela permet de réduire la mémoire utilisée et d'accélérer les calculs\n",
    "    with torch.no_grad():\n",
    "        # Itération sur le DataLoader de test (chaque itération correspond à un lot de données)\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            # Conversion des étiquettes de classe en représentation one-hot (chaque étiquette devient un vecteur binaire)\n",
    "            # 'num_classes=10' spécifie qu'il y a 10 classes pour la classification\n",
    "            targets = torch.nn.functional.one_hot(targets, num_classes=10).float()\n",
    "\n",
    "            # Déplacement des données vers le bon appareil (GPU ou CPU)\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "\n",
    "            # Passage des entrées dans le modèle pour obtenir les prédictions\n",
    "            outputs = net(inputs)\n",
    "\n",
    "            # Calcul de la perte entre les sorties du modèle et les étiquettes cibles\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            # Ajout de la perte de ce lot au total de la perte de test\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            # Prédiction de la classe (index de la classe avec la probabilité la plus élevée)\n",
    "            _, predicted = outputs.max(1)\n",
    "\n",
    "            # Mise à jour du nombre total d'exemples traités\n",
    "            total += targets.size(0)\n",
    "\n",
    "            # Mise à jour du nombre de prédictions correctes\n",
    "            correct += predicted.eq(targets.argmax(1)).sum().item()\n",
    "\n",
    "            # Affichage de l'état d'avancement du test si l'option verbose est activée\n",
    "            if args.verbose:\n",
    "                # Affiche la perte moyenne et la précision jusqu'à l'instant\n",
    "                progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
    "                             % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
    "\n",
    "    # Calcul de la précision en pourcentage\n",
    "    acc = 100. * correct / total\n",
    "\n",
    "    # Si l'option 'save_checkpoint' est activée, on enregistre l'état du modèle\n",
    "    if save_checkpoint:\n",
    "        print('Saving..')\n",
    "        # Création de l'état du modèle à sauvegarder\n",
    "        state = {\n",
    "            'net': net.state_dict(),   # Poids du modèle (état du réseau de neurones)\n",
    "            'acc': acc,                 # Précision sur l'ensemble de test\n",
    "            'epoch': epoch,             # Numéro de l'époque actuelle\n",
    "        }\n",
    "        # Sauvegarde de l'état dans un fichier .pth (format PyTorch)\n",
    "        torch.save(state, os.path.join(args.ckpt_path, '%s.pth'%model_name))\n",
    "        \n",
    "        # Mise à jour de la meilleure précision observée\n",
    "        best_acc = acc\n",
    "\n",
    "    # Retourne la précision en pourcentage et la perte moyenne pour l'ensemble de test\n",
    "    return 100. * correct / total, test_loss / (batch_idx + 1)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Création d'un parseur d'arguments pour la ligne de commande\n",
    "parser = argparse.ArgumentParser(description='PyTorch MNIST Double Descent Curve')\n",
    "\n",
    "# Ajout d'un argument pour définir le niveau de verbosité (affichage des détails)\n",
    "parser.add_argument('--verbose', default=0, type=int, help='level of verbosity')\n",
    "\n",
    "# Ajout d'un argument pour permettre la réutilisation des paramètres (option booléenne)\n",
    "parser.add_argument('--reuse', action='store_true', help='parameter reuse')\n",
    "\n",
    "# Spécification du répertoire des données d'entrée (dossier où les données seront lues)\n",
    "parser.add_argument('--data_path', default='./data', type=str, help='data directory')\n",
    "\n",
    "# Spécification du répertoire pour les modèles sauvegardés (checkpoints)\n",
    "parser.add_argument('--ckpt_path', default='./ckpt', type=str, help='checkpoint directory')\n",
    "\n",
    "# Spécification du répertoire pour les fichiers de logs\n",
    "parser.add_argument('--log_path', default='./log', type=str, help='log directory')\n",
    "\n",
    "# Analyse des arguments passés à la ligne de commande\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Vérification et création des répertoires nécessaires si ils n'existent pas déjà\n",
    "\n",
    "# Si le répertoire pour les données n'existe pas, on le crée\n",
    "if not os.path.isdir(args.data_path):\n",
    "    os.mkdir(args.data_path)\n",
    "\n",
    "# Si le répertoire pour les checkpoints n'existe pas, on le crée\n",
    "if not os.path.isdir(args.ckpt_path):\n",
    "    os.mkdir(args.ckpt_path)\n",
    "\n",
    "# Si le répertoire pour les logs n'existe pas, on le crée\n",
    "if not os.path.isdir(args.log_path):\n",
    "    os.mkdir(args.log_path)\n",
    "\n",
    "# Détermination du périphérique utilisé pour l'exécution : GPU si disponible, sinon CPU\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "# Préparation des données\n",
    "# Affichage d'un message indiquant que les données sont en train de se préparer\n",
    "print('==> Preparing data..')\n",
    "\n",
    "# Définition des transformations à appliquer sur les images d'entraînement\n",
    "transform_train = transforms.Compose([\n",
    "    # Transformation des images en tenseurs\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Définition des transformations à appliquer sur les images de test\n",
    "transform_test = transforms.Compose([\n",
    "    # Transformation des images en tenseurs\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "\n",
    "# Chargement du jeu de données MNIST pour l'entraînement\n",
    "trainset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path,     # Chemin vers les données, défini précédemment dans les arguments\n",
    "    train=True,              # Indique qu'il s'agit de la partition d'entraînement (True pour entraînement, False pour test)\n",
    "    download=True,           # Si les données ne sont pas présentes localement, elles seront téléchargées\n",
    "    transform=transform_train  # Transformation à appliquer aux images d'entraînement (convertir en tenseur)\n",
    ")\n",
    "\n",
    "# Création d'un sous-ensemble du jeu de données d'entraînement en ne prenant que les 4000 premiers exemples\n",
    "trainset = torch.utils.data.Subset(trainset, indices=np.arange(4000))\n",
    "\n",
    "# Création d'un DataLoader pour charger les données d'entraînement par lot\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    trainset,                # Le sous-ensemble des données d'entraînement\n",
    "    batch_size=128,          # Taille de chaque lot (128 images par lot)\n",
    "    shuffle=True,            # Mélange des données avant chaque époque pour éviter les biais dans l'entraînement\n",
    "    num_workers=2            # Nombre de processus parallèles pour charger les données (accélère le chargement)\n",
    ")\n",
    "\n",
    "# Chargement du jeu de données MNIST pour le test\n",
    "testset = torchvision.datasets.MNIST(\n",
    "    root=args.data_path,     # Chemin vers les données\n",
    "    train=False,             # Indique qu'il s'agit de la partition de test\n",
    "    download=True,           # Si les données ne sont pas présentes localement, elles seront téléchargées\n",
    "    transform=transform_test  # Transformation à appliquer aux images de test (convertir en tenseur)\n",
    ")\n",
    "\n",
    "# Création d'un DataLoader pour charger les données de test par lot\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    testset,                 # Jeu de données de test\n",
    "    batch_size=100,          # Taille de chaque lot (100 images par lot)\n",
    "    shuffle=False,           # Pas besoin de mélanger les données de test, car elles sont utilisées pour évaluation\n",
    "    num_workers=2            # Nombre de processus parallèles pour charger les données\n",
    ")\n",
    "\n",
    "# Liste des tailles de couches cachées à tester dans l'architecture du modèle\n",
    "n_hidden_units = [1, 3, 5, 7, 9, 10, 20, 30, 40, 45, 47, 49, 50, 51, 53, 55, 60, 70, 80, 90, \n",
    "                  100, 110, 130, 150, 170, 200, 250]\n",
    "\n",
    "# Nombre d'époques d'entraînement (6000 époques)\n",
    "n_epoch = 6000\n",
    "\n",
    "# Boucle pour tester différentes tailles de couches cachées\n",
    "for n_hidden_unit in n_hidden_units:\n",
    "    # Création du modèle (réseau de neurones) avec le nombre de neurones spécifié dans n_hidden_unit\n",
    "    net = simple_FC(n_hidden_unit)  # simple_FC est une fonction qui génère un réseau avec n_hidden_unit neurones cachés\n",
    "    # Affichage du nombre total de paramètres du modèle\n",
    "    print('Number of parameters: %d' % sum(p.numel() for p in net.parameters()))\n",
    "    \n",
    "    # Envoi du modèle sur le périphérique (GPU ou CPU)\n",
    "    net = net.cuda()  # Envoie le modèle sur le GPU si disponible (CUDA)\n",
    "    net = net.to(device)  # Envoie le modèle vers le périphérique 'cuda' ou 'cpu', selon le cas\n",
    "    \n",
    "    # Configuration spécifique pour les GPU si CUDA est disponible\n",
    "    if device == 'cuda':\n",
    "        net = net.cuda()  # Envoie le modèle sur le GPU\n",
    "        cudnn.benchmark = True  # Active l'optimisation pour les architectures de GPU avec des tailles d'entrée fixes\n",
    "    \n",
    "    ### Initialisation des poids du modèle ###\n",
    "    if n_hidden_unit == 1:  # Si le réseau a 1 neurone caché, c'est le plus petit réseau\n",
    "        # Initialisation des poids avec la méthode Xavier (uniforme) pour les couches cachées et la couche de sortie\n",
    "        torch.nn.init.xavier_uniform_(net.features[1].weight, gain=1.0)\n",
    "        torch.nn.init.xavier_uniform_(net.classifier.weight, gain=1.0)\n",
    "    elif n_hidden_unit > 50:  # Si le nombre de neurones cachés est supérieur à 50, on utilise une initialisation normale\n",
    "        # Initialisation des poids avec une distribution normale (moyenne=0, écart-type=0.1) pour éviter des valeurs extrêmes\n",
    "        torch.nn.init.normal_(net.features[1].weight, mean=0.0, std=0.1)\n",
    "        torch.nn.init.normal_(net.classifier.weight, mean=0.0, std=0.1)\n",
    "    else:  # Si le nombre de neurones cachés est entre 1 et 50, on applique une initialisation normale\n",
    "        torch.nn.init.normal_(net.features[1].weight, mean=0.0, std=0.1)\n",
    "        torch.nn.init.normal_(net.classifier.weight, mean=0.0, std=0.1)\n",
    "        \n",
    "        # Si l'argument --reuse est passé, on réutilise les poids d'un modèle précédent pour l'initialisation\n",
    "        if args.reuse:\n",
    "            print('use previous checkpoints to initialize the weights')\n",
    "            i = 1  # On commence avec le modèle précédent le plus proche\n",
    "            while not os.path.exists(os.path.join(args.ckpt_path, 'simple_FC_%d.pth' % (n_hidden_unit - i))):\n",
    "                print('loading from simple_FC_%d.pth' % (n_hidden_unit - i))  # Chargement du modèle précédent\n",
    "                i += 1  # On cherche de plus en plus en arrière dans les checkpoints\n",
    "            # Chargement du checkpoint correspondant\n",
    "            checkpoint = torch.load(os.path.join(args.ckpt_path, 'simple_FC_%d.pth' % (n_hidden_unit - i)))\n",
    "            with torch.no_grad():\n",
    "                # Copie des poids du modèle préexistant dans le modèle actuel\n",
    "                net.features[1].weight[:n_hidden_unit - i, :].copy_(checkpoint['net']['features.1.weight'])\n",
    "                net.features[1].bias[:n_hidden_unit - i].copy_(checkpoint['net']['features.1.bias'])\n",
    "                net.classifier.weight[:, :n_hidden_unit - i].copy_(checkpoint['net']['classifier.weight'])\n",
    "                net.classifier.bias.copy_(checkpoint['net']['classifier.bias'])\n",
    "    \n",
    "    ### Entraînement et test du modèle ###\n",
    "    best_acc = 0  # Initialisation de la meilleure précision obtenue\n",
    "    start_epoch = 0  # Début de l'entraînement à l'époque 0\n",
    "    criterion = nn.MSELoss()  # Fonction de perte, ici l'erreur quadratique moyenne (MSE)\n",
    "    optimizer = optim.SGD(net.parameters(), lr=0.01, momentum=0.95)  # Optimiseur SGD avec un taux d'apprentissage de 0.01 et momentum de 0.95\n",
    "    \n",
    "    # Boucle d'entraînement\n",
    "    for epoch in range(start_epoch, start_epoch + n_epoch):\n",
    "        # Mise à jour du taux d'apprentissage à chaque 500 itérations\n",
    "        if (epoch + 1) % 500 == 0:\n",
    "            if n_hidden_unit <= 50:  # Ajustement du taux d'apprentissage pour les petits réseaux\n",
    "                optimizer.param_groups[0]['lr'] = optimizer.param_groups[0]['lr'] * 0.9  # Réduit le taux d'apprentissage de 10%\n",
    "        \n",
    "        # Entraînement sur l'époque courante\n",
    "        train_acc, train_loss = train(epoch, net)\n",
    "        \n",
    "        # Condition d'arrêt anticipé (early stopping) : arrêt si la précision d'entraînement atteint 100% ou si on atteint la dernière époque\n",
    "        if n_hidden_unit <= 50 and train_acc == 1 or epoch == start_epoch + n_epoch - 1:\n",
    "            # Test du modèle et sauvegarde des poids\n",
    "            test_acc, test_loss = test(epoch, net, 'simple_FC_%d' % (n_hidden_unit), save_checkpoint=True)\n",
    "            print('classification error reaches 0, stop training')  # Affichage du message d'arrêt\n",
    "            break\n",
    "    \n",
    "    # Affichage des résultats de l'entraînement et du test\n",
    "    print('Training Loss: %.3f | Acc: %.3f%%' % (train_loss, train_acc))\n",
    "    print('Test Loss: %.3f | Acc: %.3f%%\\n' % (test_loss, test_acc))\n",
    "    \n",
    "    # Sauvegarde des résultats dans un fichier texte\n",
    "    with open(os.path.join(args.log_path, 'FC_%d.txt' % n_hidden_unit), 'w') as fw:\n",
    "        # Écriture du nombre de paramètres du modèle\n",
    "        fw.write('Number of parameters: %d\\n' % sum(p.numel() for p in net.parameters()))\n",
    "        # Écriture des résultats d'entraînement\n",
    "        fw.write('Training Loss: %.3f | Acc: %.3f%%\\n' % (train_loss, train_acc))\n",
    "        # Écriture des résultats de test\n",
    "        fw.write('Test Loss: %.3f | Acc: %.3f%%\\n' % (test_loss, test_acc))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Récupération et tri des noms des modèles à partir des fichiers dans le dossier de log\n",
    "model_names = sorted([int(fn.split('_')[1].split('.')[0]) for fn in os.listdir(args.log_path)])\n",
    "\n",
    "# Initialisation des dictionnaires pour stocker les pertes (losses), les précisions (accs), et le nombre de paramètres pour chaque modèle\n",
    "train_losses = {model_name: 0. for model_name in model_names}\n",
    "test_losses = {model_name: 0. for model_name in model_names}\n",
    "train_accs = {model_name: 0. for model_name in model_names}\n",
    "test_accs = {model_name: 0. for model_name in model_names}\n",
    "n_params = {model_name: 0. for model_name in model_names}\n",
    "\n",
    "\n",
    "# Pour chaque modèle, ouvrir son fichier log et extraire les informations de performance et les paramètres\n",
    "for model_name in model_names:\n",
    "    with open(os.path.join('log', 'FC_%d.txt' % (model_name))) as f:\n",
    "        for line in f:\n",
    "            if line.startswith('Number'):\n",
    "                # Si la ligne commence par 'Number', c'est la ligne qui contient le nombre de paramètres du modèle\n",
    "                n_params[model_name] = float(line.rstrip().split()[-1])  # Extraire le dernier élément de la ligne (nombre de paramètres)\n",
    "            \n",
    "            if line.startswith('Training'):\n",
    "                # Si la ligne commence par 'Training', c'est une ligne de perte et précision pendant l'entraînement\n",
    "                loss = re.search(r'Loss: (.*?) \\|', line).group(1)  # Utilisation de regex pour extraire la perte\n",
    "                train_losses[model_name] = float(loss)  # Stocker la perte d'entraînement dans le dictionnaire\n",
    "                acc = re.search(r'Acc: (.*?)\\%', line).group(1)  # Utilisation de regex pour extraire la précision\n",
    "                train_accs[model_name] = float(acc)  # Stocker la précision d'entraînement dans le dictionnaire\n",
    "\n",
    "            if line.startswith('Test'):\n",
    "                # Si la ligne commence par 'Test', c'est une ligne de perte et précision pendant le test\n",
    "                loss = re.search(r'Loss: (.*?) \\|', line).group(1)  # Utilisation de regex pour extraire la perte\n",
    "                test_losses[model_name] = float(loss)  # Stocker la perte de test dans le dictionnaire\n",
    "                acc = re.search(r'Acc: (.*?)\\%', line).group(1)  # Utilisation de regex pour extraire la précision\n",
    "                test_accs[model_name] = float(acc)  # Stocker la précision de test dans le dictionnaire\n",
    "\n",
    "\n",
    "\n",
    "# Nettoyage et préparation d'un nouveau graphique pour afficher la perte (loss) en fonction du nombre de paramètres\n",
    "plt.clf()  # Efface la figure précédente, si elle existe\n",
    "fig = plt.figure()  # Crée une nouvelle figure\n",
    "ax = plt.subplot(111)  # Crée un sous-graphe (axes) dans la figure (1 ligne, 1 colonne, 1ère position)\n",
    "\n",
    "# Tracé de la courbe de perte d'entraînement en fonction du nombre de paramètres\n",
    "plt.plot([n_params[model_name] for model_name in model_names], \n",
    "         [train_losses[model_name] for model_name in model_names], \n",
    "         marker='o', label='train', color='#e31a1c')\n",
    "# Tracé de la courbe de perte de test en fonction du nombre de paramètres\n",
    "plt.plot([n_params[model_name] for model_name in model_names], \n",
    "         [test_losses[model_name] for model_name in model_names], \n",
    "         marker='o', label='test', color='#1f78b4')\n",
    "\n",
    "# Ajout d'un label à l'axe des ordonnées (loss)\n",
    "plt.ylabel('loss')\n",
    "\n",
    "# Ajuste la mise en page du graphique pour éviter que les éléments ne se chevauchent\n",
    "box = ax.get_position()  # Récupère la position actuelle du sous-graphe (axes)\n",
    "plt.tight_layout()  # Ajuste automatiquement les paramètres de la figure pour éviter que les éléments ne se chevauchent\n",
    "ax.set_position([box.x0, box.y0, box.width, box.height * 0.9])  # Réduit la hauteur du sous-graphe (axes) pour faire de la place à la légende\n",
    "\n",
    "# Ajout d'une légende en haut du graphique, avec des options de mise en forme\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.25), fancybox=True, ncol=4)\n",
    "\n",
    "# Enregistrement du graphique dans un fichier, en fonction de l'argument 'reuse'\n",
    "if args.reuse:\n",
    "    plt.savefig('MNIST_double_descent_loss_w_weight_reuse.png')  # Sauvegarde le graphique avec le titre adapté si 'reuse' est activé\n",
    "else:\n",
    "    plt.savefig('MNIST_double_descent_loss_wo_weight_reuse.png')  # Sauvegarde le graphique sans réutilisation des poids\n",
    "\n",
    "# Nettoyage et préparation d'un nouveau graphique pour afficher la précision (accuracy) en fonction du nombre de paramètres\n",
    "plt.clf()  # Efface la figure précédente\n",
    "fig = plt.figure()  # Crée une nouvelle figure\n",
    "ax = plt.subplot(111)  # Crée un sous-graphe (axes) dans la figure (1 ligne, 1 colonne, 1ère position)\n",
    "\n",
    "# Tracé de la courbe de précision d'entraînement en fonction du nombre de paramètres\n",
    "plt.plot([n_params[model_name] for model_name in model_names], \n",
    "         [train_accs[model_name] for model_name in model_names], \n",
    "         marker='o', label='train', color='#e31a1c')\n",
    "# Tracé de la courbe de précision de test en fonction du nombre de paramètres\n",
    "plt.plot([n_params[model_name] for model_name in model_names], \n",
    "         [test_accs[model_name] for model_name in model_names], \n",
    "         marker='o', label='test', color='#1f78b4')\n",
    "\n",
    "# Ajout d'un label à l'axe des ordonnées (accuracy)\n",
    "plt.ylabel('accuracy')\n",
    "\n",
    "# Ajuste la mise en page du graphique pour éviter que les éléments ne se chevauchent\n",
    "box = ax.get_position()  # Récupère la position actuelle du sous-graphe (axes)\n",
    "plt.tight_layout()  # Ajuste automatiquement les paramètres de la figure\n",
    "ax.set_position([box.x0, box.y0, box.width, box.height * 0.9])  # Réduit la hauteur pour faire de la place à la légende\n",
    "\n",
    "# Ajout d'une légende en haut du graphique, avec des options de mise en forme\n",
    "plt.legend(loc='upper center', bbox_to_anchor=(0.5, 1.25), fancybox=True, ncol=4)\n",
    "\n",
    "# Enregistrement du graphique dans un fichier, en fonction de l'argument 'reuse'\n",
    "if args.reuse:\n",
    "    plt.savefig('MNIST_double_descent_accuracy_w_weight_reuse.png')  # Sauvegarde du graphique avec réutilisation des poids\n",
    "else:\n",
    "    plt.savefig('MNIST_double_descent_accuracy_wo_weight_reuse.png')  # Sauvegarde du graphique sans réutilisation des poids\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
